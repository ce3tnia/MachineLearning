{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MachineLearning5",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1S1PySgbaDLkRfhbykDTq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ce3tnia/MachineLearning/blob/master/MachineLearning5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzp7-8QMVTBa",
        "outputId": "4e35bd6d-6861-4807-b28e-57c13520b88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deb5ICsKWSuX"
      },
      "source": [
        "# **Preprocessing** **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HgQGFD3VsGK",
        "outputId": "9caa74ec-d8dc-4f82-f15d-1e00e4e92f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#import data\n",
        "df = pd.read_csv('/content/drive/My Drive/MachineLearning/Iris.csv')\n",
        "#tampilan 5 data terakhir\n",
        "df.tail()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  SepalLengthCm  ...  PetalWidthCm         Species\n",
              "145  146            6.7  ...           2.3  Iris-virginica\n",
              "146  147            6.3  ...           1.9  Iris-virginica\n",
              "147  148            6.5  ...           2.0  Iris-virginica\n",
              "148  149            6.2  ...           2.3  Iris-virginica\n",
              "149  150            5.9  ...           1.8  Iris-virginica\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX6fGaTUYLZG",
        "outputId": "70221e0e-5275-44ac-c96d-6e4e7567c5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#hapus atribut yang tidak digunakan\n",
        "df.drop(['Id'], axis=1, inplace=True)\n",
        "\n",
        "#tampilkan 5 data pertama\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAJWpx5uYzHw",
        "outputId": "798619be-06d1-4280-a866-9a940c2c8d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#bagi menjadi atribut dan label\n",
        "x = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
        "y = df['Species']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "len(x_test), len(x_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZxP3Xofa62D",
        "outputId": "a1d3fd34-a6f5-4483-b54b-3293044218b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147     Iris-virginica\n",
              "13         Iris-setosa\n",
              "127     Iris-virginica\n",
              "91     Iris-versicolor\n",
              "35         Iris-setosa\n",
              "            ...       \n",
              "64     Iris-versicolor\n",
              "107     Iris-virginica\n",
              "34         Iris-setosa\n",
              "121     Iris-virginica\n",
              "138     Iris-virginica\n",
              "Name: Species, Length: 120, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_tASFkQxgyE"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EljmPrgbfqm",
        "outputId": "63b1b555-9125-41b1-be8f-80f3767a473b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "#buat model\n",
        "model_svm = svm.SVC()\n",
        "#training model\n",
        "model_svm.fit(x_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJnJBFUzcDY_",
        "outputId": "7429df87-0d6f-4ef1-d236-8a622dc9e4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#prediksi model\n",
        "pred_svm = model_svm.predict(x_test)\n",
        "#evaluasi dengan data text\n",
        "accuracy = (pred_svm == y_test).sum()/len(y_test)\n",
        "accuracy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohkleE_xcuQX",
        "outputId": "bdc42857-3820-40ef-e397-7ecc3b0ccdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(pred_svm, y_test)\n",
        "cm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13,  0,  0],\n",
              "       [ 0,  6,  0],\n",
              "       [ 0,  1, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V25au10fxllv"
      },
      "source": [
        "# **ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHBGW70yA1c"
      },
      "source": [
        "# **SKLearn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDys6ACQxjjI",
        "outputId": "0d15fbaf-567e-4515-d7fc-a4634623be36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "#buat model\n",
        "model_mlp = MLPClassifier(hidden_layer_sizes=(8, 16, 32, 64, 32, 8, 4))\n",
        "#training model\n",
        "model_mlp.fit(x_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(8, 16, 32, 64, 32, 8, 4),\n",
              "              learning_rate='constant', learning_rate_init=0.001, max_fun=15000,\n",
              "              max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "              nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
              "              shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
              "              verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjCMJJIPSh2L",
        "outputId": "ab9d40c5-a95e-46a9-a3b7-9010da751eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#predict model\n",
        "pred_mlp = model_mlp.predict(x_test)\n",
        "\n",
        "#evaluate using data test\n",
        "accuracy = (pred_mlp == y_test).sum()/len(y_test)\n",
        "accuracy"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiYR7O89Tt5E"
      },
      "source": [
        "# **Keras Tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSE0BBTLTtfi",
        "outputId": "6ecc5483-e040-4beb-dbaf-bb3bc53d223e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#import data\n",
        "df = pd.read_csv('/content/drive/My Drive/MachineLearning/Iris.csv')\n",
        "#tampilan 5 data terakhir\n",
        "df.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  SepalLengthCm  ...  PetalWidthCm         Species\n",
              "145  146            6.7  ...           2.3  Iris-virginica\n",
              "146  147            6.3  ...           1.9  Iris-virginica\n",
              "147  148            6.5  ...           2.0  Iris-virginica\n",
              "148  149            6.2  ...           2.3  Iris-virginica\n",
              "149  150            5.9  ...           1.8  Iris-virginica\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmlCHFR1YCXR",
        "outputId": "8da1ea22-5f2a-4177-90eb-8738aa04149a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "#hapus atribut yang tidak digunakan\n",
        "df.drop(['Id'], axis=1, inplace=True)\n",
        "\n",
        "#tampilkan 5 data pertama\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPf60pg4YYHZ",
        "outputId": "4dd515c0-32a6-4c42-f735-2c0307963d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#bagi menjadi atribut dan label\n",
        "x = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
        "y = df['Species']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y1 = encoder.fit_transform(y)\n",
        "\n",
        "y = pd.get_dummies(y1).values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split (x, y, test_size=0.2)\n",
        "x_train, x_val, y_train, y_val = train_test_split (x_train, y_train, test_size=0.2)\n",
        "\n",
        "len(x_test), len(x_train), len(x_val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 96, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33YbdJJBbqq0",
        "outputId": "19b31db4-b4eb-41a1-89d9-0b0d8fe1aff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z8fP2LtINwJ",
        "outputId": "3930e62f-63ed-48a3-f602-5b15a2e7b332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(10, activation='relu', input_shape=(4,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                50        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 21        \n",
            "=================================================================\n",
            "Total params: 213\n",
            "Trainable params: 213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXwH82P5QQpx"
      },
      "source": [
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VILw9joBRLAn",
        "outputId": "87075c24-79c3-490d-d023-d257094b1567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=200, validation_data=(x_val, y_val))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 1.1558 - accuracy: 0.2917 - val_loss: 1.0675 - val_accuracy: 0.2500\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.1365 - accuracy: 0.3854 - val_loss: 1.0708 - val_accuracy: 0.2917\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.1222 - accuracy: 0.3958 - val_loss: 1.0784 - val_accuracy: 0.3333\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.1086 - accuracy: 0.4062 - val_loss: 1.0841 - val_accuracy: 0.2500\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0967 - accuracy: 0.3854 - val_loss: 1.0849 - val_accuracy: 0.2500\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0857 - accuracy: 0.3854 - val_loss: 1.0848 - val_accuracy: 0.2500\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0756 - accuracy: 0.3854 - val_loss: 1.0782 - val_accuracy: 0.2500\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.0648 - accuracy: 0.3854 - val_loss: 1.0722 - val_accuracy: 0.2500\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0560 - accuracy: 0.3854 - val_loss: 1.0677 - val_accuracy: 0.2500\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0469 - accuracy: 0.3854 - val_loss: 1.0597 - val_accuracy: 0.2500\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0382 - accuracy: 0.3854 - val_loss: 1.0542 - val_accuracy: 0.2500\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0291 - accuracy: 0.3854 - val_loss: 1.0464 - val_accuracy: 0.2500\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0203 - accuracy: 0.3854 - val_loss: 1.0385 - val_accuracy: 0.2500\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.0114 - accuracy: 0.3854 - val_loss: 1.0325 - val_accuracy: 0.2500\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0033 - accuracy: 0.3854 - val_loss: 1.0250 - val_accuracy: 0.2500\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9963 - accuracy: 0.3854 - val_loss: 1.0183 - val_accuracy: 0.2500\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9894 - accuracy: 0.3854 - val_loss: 1.0148 - val_accuracy: 0.2500\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9808 - accuracy: 0.3854 - val_loss: 1.0078 - val_accuracy: 0.2500\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.9731 - accuracy: 0.3854 - val_loss: 1.0024 - val_accuracy: 0.2500\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9656 - accuracy: 0.4271 - val_loss: 0.9956 - val_accuracy: 0.2917\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9579 - accuracy: 0.4688 - val_loss: 0.9918 - val_accuracy: 0.2917\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9505 - accuracy: 0.4896 - val_loss: 0.9885 - val_accuracy: 0.2917\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.9427 - accuracy: 0.5104 - val_loss: 0.9827 - val_accuracy: 0.3750\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9348 - accuracy: 0.5417 - val_loss: 0.9754 - val_accuracy: 0.4167\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9271 - accuracy: 0.5729 - val_loss: 0.9677 - val_accuracy: 0.4167\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9192 - accuracy: 0.6354 - val_loss: 0.9603 - val_accuracy: 0.5000\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9119 - accuracy: 0.6458 - val_loss: 0.9542 - val_accuracy: 0.5000\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9047 - accuracy: 0.6667 - val_loss: 0.9463 - val_accuracy: 0.5000\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8990 - accuracy: 0.6771 - val_loss: 0.9443 - val_accuracy: 0.4583\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8917 - accuracy: 0.6562 - val_loss: 0.9407 - val_accuracy: 0.4583\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8852 - accuracy: 0.6667 - val_loss: 0.9295 - val_accuracy: 0.5000\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8779 - accuracy: 0.6771 - val_loss: 0.9234 - val_accuracy: 0.5000\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.8712 - accuracy: 0.6771 - val_loss: 0.9158 - val_accuracy: 0.5000\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8654 - accuracy: 0.6771 - val_loss: 0.9098 - val_accuracy: 0.5000\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.8589 - accuracy: 0.6771 - val_loss: 0.9029 - val_accuracy: 0.5000\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8528 - accuracy: 0.6771 - val_loss: 0.8959 - val_accuracy: 0.5000\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8469 - accuracy: 0.6875 - val_loss: 0.8854 - val_accuracy: 0.5000\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8409 - accuracy: 0.6979 - val_loss: 0.8768 - val_accuracy: 0.5000\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8349 - accuracy: 0.6979 - val_loss: 0.8671 - val_accuracy: 0.5000\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8287 - accuracy: 0.7083 - val_loss: 0.8615 - val_accuracy: 0.5000\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8235 - accuracy: 0.7083 - val_loss: 0.8518 - val_accuracy: 0.5000\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8183 - accuracy: 0.7083 - val_loss: 0.8486 - val_accuracy: 0.5000\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8117 - accuracy: 0.7083 - val_loss: 0.8429 - val_accuracy: 0.5000\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8066 - accuracy: 0.7188 - val_loss: 0.8355 - val_accuracy: 0.5417\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.8012 - accuracy: 0.7292 - val_loss: 0.8315 - val_accuracy: 0.5000\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7963 - accuracy: 0.7292 - val_loss: 0.8243 - val_accuracy: 0.5417\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7914 - accuracy: 0.7292 - val_loss: 0.8231 - val_accuracy: 0.5000\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7865 - accuracy: 0.7188 - val_loss: 0.8203 - val_accuracy: 0.5000\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7817 - accuracy: 0.7292 - val_loss: 0.8108 - val_accuracy: 0.5833\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7773 - accuracy: 0.7292 - val_loss: 0.8074 - val_accuracy: 0.5417\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7720 - accuracy: 0.7292 - val_loss: 0.8012 - val_accuracy: 0.5833\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7677 - accuracy: 0.7396 - val_loss: 0.7949 - val_accuracy: 0.5833\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7632 - accuracy: 0.7396 - val_loss: 0.7895 - val_accuracy: 0.5833\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7591 - accuracy: 0.7500 - val_loss: 0.7841 - val_accuracy: 0.5833\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7563 - accuracy: 0.7500 - val_loss: 0.7753 - val_accuracy: 0.6250\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7511 - accuracy: 0.7604 - val_loss: 0.7746 - val_accuracy: 0.5833\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7470 - accuracy: 0.7396 - val_loss: 0.7713 - val_accuracy: 0.5833\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.7428 - accuracy: 0.7396 - val_loss: 0.7659 - val_accuracy: 0.6250\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.7391 - accuracy: 0.7500 - val_loss: 0.7615 - val_accuracy: 0.6250\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.7350 - accuracy: 0.7604 - val_loss: 0.7548 - val_accuracy: 0.6667\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7318 - accuracy: 0.7812 - val_loss: 0.7449 - val_accuracy: 0.6667\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.7276 - accuracy: 0.7917 - val_loss: 0.7386 - val_accuracy: 0.7917\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7239 - accuracy: 0.7917 - val_loss: 0.7379 - val_accuracy: 0.6667\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.7198 - accuracy: 0.7917 - val_loss: 0.7351 - val_accuracy: 0.6667\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7160 - accuracy: 0.7812 - val_loss: 0.7305 - val_accuracy: 0.6667\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7124 - accuracy: 0.7917 - val_loss: 0.7255 - val_accuracy: 0.7083\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7088 - accuracy: 0.7917 - val_loss: 0.7212 - val_accuracy: 0.7083\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7050 - accuracy: 0.7917 - val_loss: 0.7176 - val_accuracy: 0.7500\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7016 - accuracy: 0.8021 - val_loss: 0.7122 - val_accuracy: 0.7917\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6982 - accuracy: 0.8125 - val_loss: 0.7094 - val_accuracy: 0.7917\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6962 - accuracy: 0.8333 - val_loss: 0.6977 - val_accuracy: 0.8750\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.8438 - val_loss: 0.6922 - val_accuracy: 0.8750\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6875 - accuracy: 0.8646 - val_loss: 0.6914 - val_accuracy: 0.8750\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6843 - accuracy: 0.8229 - val_loss: 0.6917 - val_accuracy: 0.8750\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6802 - accuracy: 0.8229 - val_loss: 0.6862 - val_accuracy: 0.8750\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6767 - accuracy: 0.8333 - val_loss: 0.6814 - val_accuracy: 0.8750\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6729 - accuracy: 0.8438 - val_loss: 0.6773 - val_accuracy: 0.8750\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6695 - accuracy: 0.8750 - val_loss: 0.6727 - val_accuracy: 0.8750\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.8854 - val_loss: 0.6658 - val_accuracy: 0.8750\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6629 - accuracy: 0.8750 - val_loss: 0.6650 - val_accuracy: 0.8750\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6600 - accuracy: 0.8750 - val_loss: 0.6656 - val_accuracy: 0.8750\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6559 - accuracy: 0.8750 - val_loss: 0.6612 - val_accuracy: 0.8750\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6543 - accuracy: 0.8854 - val_loss: 0.6505 - val_accuracy: 0.8750\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6492 - accuracy: 0.8958 - val_loss: 0.6485 - val_accuracy: 0.8750\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6461 - accuracy: 0.8958 - val_loss: 0.6435 - val_accuracy: 0.8750\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6438 - accuracy: 0.8958 - val_loss: 0.6460 - val_accuracy: 0.8750\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.8750 - val_loss: 0.6419 - val_accuracy: 0.8750\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6367 - accuracy: 0.8854 - val_loss: 0.6318 - val_accuracy: 0.8750\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6321 - accuracy: 0.9271 - val_loss: 0.6290 - val_accuracy: 0.8750\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6292 - accuracy: 0.9271 - val_loss: 0.6223 - val_accuracy: 0.8750\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6253 - accuracy: 0.9271 - val_loss: 0.6200 - val_accuracy: 0.8750\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6220 - accuracy: 0.9062 - val_loss: 0.6177 - val_accuracy: 0.8750\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6187 - accuracy: 0.9062 - val_loss: 0.6145 - val_accuracy: 0.8750\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.6094 - val_accuracy: 0.8750\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6119 - accuracy: 0.9167 - val_loss: 0.5985 - val_accuracy: 0.9167\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6091 - accuracy: 0.9271 - val_loss: 0.5895 - val_accuracy: 0.9583\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6050 - accuracy: 0.9271 - val_loss: 0.5871 - val_accuracy: 0.9583\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6014 - accuracy: 0.9271 - val_loss: 0.5872 - val_accuracy: 0.9167\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5978 - accuracy: 0.9271 - val_loss: 0.5857 - val_accuracy: 0.9167\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5943 - accuracy: 0.9271 - val_loss: 0.5810 - val_accuracy: 0.9167\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5909 - accuracy: 0.9271 - val_loss: 0.5757 - val_accuracy: 0.9167\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.9271 - val_loss: 0.5683 - val_accuracy: 0.9583\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5840 - accuracy: 0.9271 - val_loss: 0.5654 - val_accuracy: 0.9583\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5806 - accuracy: 0.9271 - val_loss: 0.5626 - val_accuracy: 0.9583\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5772 - accuracy: 0.9271 - val_loss: 0.5550 - val_accuracy: 0.9583\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5733 - accuracy: 0.9271 - val_loss: 0.5520 - val_accuracy: 0.9583\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5696 - accuracy: 0.9271 - val_loss: 0.5460 - val_accuracy: 0.9583\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.9271 - val_loss: 0.5440 - val_accuracy: 0.9583\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5628 - accuracy: 0.9271 - val_loss: 0.5369 - val_accuracy: 0.9583\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.9271 - val_loss: 0.5317 - val_accuracy: 0.9583\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.9375 - val_loss: 0.5288 - val_accuracy: 0.9583\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5517 - accuracy: 0.9271 - val_loss: 0.5261 - val_accuracy: 0.9583\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.9271 - val_loss: 0.5212 - val_accuracy: 0.9583\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5437 - accuracy: 0.9375 - val_loss: 0.5140 - val_accuracy: 0.9583\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.9375 - val_loss: 0.5106 - val_accuracy: 0.9583\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.9375 - val_loss: 0.5033 - val_accuracy: 0.9583\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.9375 - val_loss: 0.4959 - val_accuracy: 0.9583\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5291 - accuracy: 0.9375 - val_loss: 0.4959 - val_accuracy: 0.9583\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.9375 - val_loss: 0.4902 - val_accuracy: 0.9583\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5207 - accuracy: 0.9375 - val_loss: 0.4866 - val_accuracy: 0.9583\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.9375 - val_loss: 0.4827 - val_accuracy: 0.9583\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.9375 - val_loss: 0.4763 - val_accuracy: 0.9583\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5092 - accuracy: 0.9375 - val_loss: 0.4739 - val_accuracy: 0.9583\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5039 - accuracy: 0.9375 - val_loss: 0.4661 - val_accuracy: 0.9583\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.9375 - val_loss: 0.4551 - val_accuracy: 0.9583\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.9583 - val_loss: 0.4450 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.9583 - val_loss: 0.4414 - val_accuracy: 0.9583\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4829 - accuracy: 0.9479 - val_loss: 0.4366 - val_accuracy: 0.9583\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.9375 - val_loss: 0.4351 - val_accuracy: 0.9583\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.9479 - val_loss: 0.4217 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.9583 - val_loss: 0.4112 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.9583 - val_loss: 0.4071 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.9583 - val_loss: 0.4036 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.9583 - val_loss: 0.3978 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.9583 - val_loss: 0.3869 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.9583 - val_loss: 0.3827 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.9583 - val_loss: 0.3752 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.9583 - val_loss: 0.3697 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.9583 - val_loss: 0.3630 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.9583 - val_loss: 0.3593 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.9583 - val_loss: 0.3523 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.9583 - val_loss: 0.3528 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.9583 - val_loss: 0.3404 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.9583 - val_loss: 0.3290 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3741 - accuracy: 0.9583 - val_loss: 0.3193 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3671 - accuracy: 0.9583 - val_loss: 0.3151 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3594 - accuracy: 0.9583 - val_loss: 0.3131 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.9583 - val_loss: 0.3056 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.9583 - val_loss: 0.3001 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.9583 - val_loss: 0.2948 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3318 - accuracy: 0.9583 - val_loss: 0.2856 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.9583 - val_loss: 0.2778 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3179 - accuracy: 0.9583 - val_loss: 0.2747 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3129 - accuracy: 0.9583 - val_loss: 0.2745 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3054 - accuracy: 0.9583 - val_loss: 0.2644 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3006 - accuracy: 0.9479 - val_loss: 0.2525 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2933 - accuracy: 0.9479 - val_loss: 0.2483 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2867 - accuracy: 0.9583 - val_loss: 0.2496 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2811 - accuracy: 0.9583 - val_loss: 0.2438 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2774 - accuracy: 0.9583 - val_loss: 0.2339 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2696 - accuracy: 0.9583 - val_loss: 0.2321 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2648 - accuracy: 0.9583 - val_loss: 0.2291 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2597 - accuracy: 0.9583 - val_loss: 0.2239 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2540 - accuracy: 0.9583 - val_loss: 0.2153 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2525 - accuracy: 0.9583 - val_loss: 0.2132 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2466 - accuracy: 0.9583 - val_loss: 0.2043 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2415 - accuracy: 0.9583 - val_loss: 0.2016 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2365 - accuracy: 0.9583 - val_loss: 0.2005 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2373 - accuracy: 0.9583 - val_loss: 0.2042 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2307 - accuracy: 0.9583 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2258 - accuracy: 0.9479 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2236 - accuracy: 0.9583 - val_loss: 0.1803 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2187 - accuracy: 0.9583 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2148 - accuracy: 0.9583 - val_loss: 0.1809 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2126 - accuracy: 0.9583 - val_loss: 0.1772 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2107 - accuracy: 0.9583 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2061 - accuracy: 0.9479 - val_loss: 0.1648 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2054 - accuracy: 0.9583 - val_loss: 0.1604 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2007 - accuracy: 0.9583 - val_loss: 0.1612 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1989 - accuracy: 0.9583 - val_loss: 0.1639 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1961 - accuracy: 0.9583 - val_loss: 0.1569 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1941 - accuracy: 0.9583 - val_loss: 0.1500 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1917 - accuracy: 0.9583 - val_loss: 0.1500 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1878 - accuracy: 0.9688 - val_loss: 0.1453 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1850 - accuracy: 0.9583 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.9583 - val_loss: 0.1414 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1841 - accuracy: 0.9688 - val_loss: 0.1420 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1770 - accuracy: 0.9688 - val_loss: 0.1336 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1774 - accuracy: 0.9583 - val_loss: 0.1272 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1731 - accuracy: 0.9583 - val_loss: 0.1248 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1689 - accuracy: 0.9583 - val_loss: 0.1258 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1663 - accuracy: 0.9688 - val_loss: 0.1236 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1644 - accuracy: 0.9688 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.9583 - val_loss: 0.1126 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1590 - accuracy: 0.9583 - val_loss: 0.1106 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1568 - accuracy: 0.9583 - val_loss: 0.1086 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1549 - accuracy: 0.9583 - val_loss: 0.1062 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1530 - accuracy: 0.9583 - val_loss: 0.1038 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.9583 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.9583 - val_loss: 0.0980 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp5iuypDTNmh",
        "outputId": "caabaa01-c09a-4ea2-894d-6049a5c4fa52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "#Train and validation accuracy\n",
        "plt.figure()\n",
        "plt.plot(epochs, acc, 'blue', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'black', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "#Show Plot\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a652yaccTOsq",
        "outputId": "8602f885-27d8-439e-aeb0-cfa3bf0d3f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "y_test_class = np.argmax(y_test,axis=1)\n",
        "y_pred_class = np.argmax(y_pred,axis=1)\n",
        "\n",
        "accuracy = (y_pred_class == y_test_class).sum()/len(y_test_class)\n",
        "accuracy"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcrPDwCcTW3h",
        "outputId": "d37bd7bf-e874-4cb5-a8e4-94c3ce910409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.6668122e-04, 1.1420789e-01, 8.8492543e-01],\n",
              "       [3.9900634e-02, 9.2607409e-01, 3.4025192e-02],\n",
              "       [8.7388635e-02, 8.7416977e-01, 3.8441576e-02],\n",
              "       [3.9129842e-05, 2.4454234e-02, 9.7550666e-01],\n",
              "       [9.7311413e-01, 2.6795318e-02, 9.0495108e-05],\n",
              "       [1.9493673e-02, 8.3265364e-01, 1.4785275e-01],\n",
              "       [9.7559410e-01, 2.4338026e-02, 6.7748937e-05],\n",
              "       [9.7176719e-01, 2.8126786e-02, 1.0606061e-04],\n",
              "       [3.2399911e-02, 9.1636795e-01, 5.1232144e-02],\n",
              "       [9.7427553e-01, 2.5644731e-02, 7.9653146e-05],\n",
              "       [9.7692752e-01, 2.3015566e-02, 5.6999757e-05],\n",
              "       [9.7102058e-01, 2.8864503e-02, 1.1493276e-04],\n",
              "       [1.1297762e-05, 9.3984529e-03, 9.9059021e-01],\n",
              "       [9.5975643e-01, 3.9927676e-02, 3.1585677e-04],\n",
              "       [2.9237475e-03, 5.0854647e-01, 4.8852983e-01],\n",
              "       [9.6549028e-01, 3.4312900e-02, 1.9677525e-04],\n",
              "       [7.4732096e-05, 1.8103546e-02, 9.8182172e-01],\n",
              "       [9.4851512e-01, 5.1225994e-02, 2.5898052e-04],\n",
              "       [9.6381265e-01, 3.6023881e-02, 1.6344189e-04],\n",
              "       [9.7255647e-01, 2.7346369e-02, 9.7197502e-05],\n",
              "       [8.4781684e-03, 8.8547188e-01, 1.0604995e-01],\n",
              "       [2.3195966e-05, 1.3471441e-02, 9.8650533e-01],\n",
              "       [9.6407449e-01, 3.5702724e-02, 2.2270699e-04],\n",
              "       [3.1315340e-05, 1.4465009e-02, 9.8550361e-01],\n",
              "       [9.7474355e-01, 2.5181087e-02, 7.5278382e-05],\n",
              "       [1.1055755e-02, 9.2738849e-01, 6.1555739e-02],\n",
              "       [1.1940691e-05, 8.6655291e-03, 9.9132252e-01],\n",
              "       [3.0897951e-02, 9.2893726e-01, 4.0164717e-02],\n",
              "       [9.8048156e-01, 1.9484295e-02, 3.4086130e-05],\n",
              "       [1.2982776e-02, 9.4858646e-01, 3.8430806e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTq3QsuHTa3V",
        "outputId": "d6c10753-9fc3-4fb0-a3a5-d0d0bf9fa07a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_pred_class, y_test_class)\n",
        "cm"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14,  0,  0],\n",
              "       [ 0,  9,  0],\n",
              "       [ 0,  0,  7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}